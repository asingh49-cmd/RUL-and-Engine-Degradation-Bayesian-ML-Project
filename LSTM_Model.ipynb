{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FD001 Preprocessing Pipeline\n",
    "Step 1: Load data\n",
    "Step 2: Add RUL labels to training data\n",
    "Step 3: Feature selection (drop constant sensors)\n",
    "Step 4: Normalise (z-score, fit on train, apply to test)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "DATA_DIR = \"6. Turbofan Engine Degradation Simulation Data Set/CMAPSSData\"   # folder containing the .txt files\n",
    "MAX_RUL  = 125 # piecewise-linear RUL cap (cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(data_dir: str):\n",
    "    \"\"\"\n",
    "    Loads train_FD001.txt, test_FD001.txt and RUL_FD001.txt.\n",
    "\n",
    "    The files have no headers so assign column names manually.\n",
    "    26 columns total:\n",
    "        col 1    - unit number  (engine ID)\n",
    "        col 2    - cycle        (timestep)\n",
    "        cols 3-5 - 3 operating settings\n",
    "        cols 6-26 - 21 sensor readings\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train : pd.DataFrame  full run-to-failure trajectories (100 engines)\n",
    "    test  : pd.DataFrame  trajectories cut before failure  (100 engines)\n",
    "    rul   : pd.Series     true RUL at last cycle of each test engine\n",
    "    \"\"\"\n",
    "    col_names = (\n",
    "        ['unit', 'cycle', 'os1', 'os2', 'os3'] +\n",
    "        [f's{i}' for i in range(1, 22)]\n",
    "    )\n",
    "\n",
    "    train = pd.read_csv(\n",
    "        f'{data_dir}/train_FD001.txt',\n",
    "        sep=r'\\s+', header=None, names=col_names\n",
    "    )\n",
    "    test = pd.read_csv(\n",
    "        f'{data_dir}/test_FD001.txt',\n",
    "        sep=r'\\s+', header=None, names=col_names\n",
    "    )\n",
    "    rul = pd.read_csv(\n",
    "        f'{data_dir}/RUL_FD001.txt',\n",
    "        header=None, names=['RUL']\n",
    "    )['RUL']\n",
    "\n",
    "    print(f\"Train -> {train['unit'].nunique()} engines,\"\n",
    "          f\"{len(train):,} rows, {train.shape[1]} columns\")\n",
    "    print(f\"Test -> {test['unit'].nunique()} engines,\"\n",
    "          f\"{len(test):,} rows,  {test.shape[1]} columns\")\n",
    "    print(f\"RUL -> {len(rul)} ground-truth values\")\n",
    "    print(f\"\\nTrain cycle range per engine:\")\n",
    "    cycles = train.groupby('unit')['cycle'].max()\n",
    "    print(f\"min={cycles.min()} max={cycles.max()}\"\n",
    "          f\"mean={cycles.mean():.1f} std={cycles.std():.1f}\")\n",
    "    print(f\"\\nTest RUL range:\")\n",
    "    print(f\"min={rul.min()} max={rul.max()}\"\n",
    "          f\"mean={rul.mean():.1f} std={rul.std():.1f}\")\n",
    "\n",
    "    return train, test, rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rul_column(df: pd.DataFrame, max_rul: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Appends a 'RUL' column to every row of the training DataFrame.\n",
    "\n",
    "    For each engine the true RUL at cycle t is:\n",
    "        RUL(t) = max_cycle_for_this_engine - t\n",
    "\n",
    "    For example, if engine #1 runs for 200 cycles:\n",
    "        cycle 1   → RUL = 199\n",
    "        cycle 100 → RUL = 100\n",
    "        cycle 200 → RUL = 0    (failure)\n",
    "\n",
    "    Piecewise-linear cap (MAX_RUL):\n",
    "        Any RUL above max_rul is clipped to max_rul.\n",
    "        This means early healthy cycles all get the same label (125),\n",
    "        telling the model \"don't try to be precise here, the engine is fine\".\n",
    "        The model then focuses its capacity on the degradation zone\n",
    "        where accurate prediction actually matters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df      : training DataFrame (must have 'unit' and 'cycle' columns)\n",
    "    max_rul : upper cap on RUL label (typically 125 for FD001)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df with new 'RUL' column added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Last observed cycle per engine = failure point\n",
    "    max_cycle = df.groupby('unit')['cycle'].max()\n",
    "\n",
    "    # RUL at each row = failure cycle minus current cycle\n",
    "    df['RUL'] = df.apply(\n",
    "        lambda row: max_cycle[row['unit']] - row['cycle'], axis=1\n",
    "    )\n",
    "\n",
    "    # Apply piecewise-linear cap\n",
    "    df['RUL'] = df['RUL'].clip(upper=max_rul)\n",
    "\n",
    "    print(f\"Max RUL cap applied: {max_rul} cycles\")\n",
    "    print(f\"RUL column range: {df['RUL'].min():.0f} - {df['RUL'].max():.0f}\")\n",
    "    print(f\"Rows capped at {max_rul}:\"\n",
    "          f\"{(df['RUL'] == max_rul).sum():,} \"\n",
    "          f\"({(df['RUL'] == max_rul).mean()*100:.1f}% of rows)\")\n",
    "    print(f\"Rows in degradation:\"\n",
    "          f\"{(df['RUL'] < max_rul).sum():,} \"\n",
    "          f\"({(df['RUL'] < max_rul).mean()*100:.1f}% of rows)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Step 1 — Load\n",
    "    train, test, rul = load_data(DATA_DIR)\n",
    "\n",
    "    # Step 2 — RUL labels\n",
    "    train = add_rul_column(train, max_rul=MAX_RUL)\n",
    "\n",
    "    # Step 3 — Feature selection\n",
    "    train, test, kept_sensors, dropped_sensors = select_features(train, test)\n",
    "\n",
    "    # Step 4 — Normalise\n",
    "    train, test, scaler = normalize(train, test, feature_cols=kept_sensors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
